{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings and Vector Databases with Pinecone\n",
    "\n",
    "**Embeddings** are vector representations of text. They are used to represent text in a vector space, where the distance between vectors represents the semantic similarity between the texts.\n",
    "\n",
    "**Vector Databases** are databases that store vectors and their associated metadata. They are used to store and retrieve embeddings. Vector databases are organized into indexes (also called namespaces) - similar to tables in a relational database.\n",
    "\n",
    "[Pinecone](https://www.pinecone.io/) is a vector database service that allows you to store and retrieve embeddings. It is a hosted service that allows you to scale your vector database as needed.\n",
    "\n",
    "There are two main ways to use Pinecone:\n",
    "\n",
    "1. **Store an embedding** - Store an embedding in a vector database.\n",
    "    - Embed the text you want to store.\n",
    "    - Create a document with the embedding and metadata.\n",
    "    - Store the document in a vector database.\n",
    "2. **Query a vector database** - Query a vector database for the most similar embeddings to a given query.\n",
    "    - Embed the query.\n",
    "    - Query the vector database with the embedded query.\n",
    "    - Retrieve the most similar embeddings to the query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Pinecone and OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pinecone openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "from datetime import datetime, timezone\n",
    "from pinecone import Pinecone\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY=os.getenv(\"PINECONE_API_KEY\") # Pinecone API key\n",
    "PINECONE_INDEX_NAME=os.getenv(\"PINECONE_INDEX_NAME\") # Name of the vector database index\n",
    "PINECONE_NAMESPACE=os.getenv(\"PINECONE_NAMESPACE\") # Namespace in your index on Pinecone.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Pinecone and OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Pinecone for vector database\n",
    "pc = Pinecone(PINECONE_API_KEY)\n",
    "# Initialize the vector database index\n",
    "index = pc.Index(PINECONE_INDEX_NAME)\n",
    "# Initialize OpenAI for embeddings \n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Store an embedding\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_to_store = \"I like cars.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OpenAI embeddings\n",
    "def get_embeddings(string_to_embed):\n",
    "    response = client.embeddings.create(\n",
    "        input=string_to_embed,\n",
    "        model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = get_embeddings(string_to_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Vector representation of {string_to_store}: \\n\", vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the vector metadata to store in the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = \"1234\"\n",
    "path = \"user/{user_id}/recall/{event_id}\"\n",
    "current_time = datetime.now(tz=timezone.utc)\n",
    "path = path.format(\n",
    "    user_id=user_id,\n",
    "    event_id=str(uuid.uuid4()),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the vector document to be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build document dictionary\n",
    "documents = [\n",
    "    {\n",
    "        \"id\": str(uuid.uuid4()),\n",
    "        \"values\": vector,\n",
    "        \"metadata\": {\n",
    "            \"payload\": string_to_store,\n",
    "            \"path\": path,\n",
    "            \"timestamp\": str(current_time),\n",
    "            \"type\": \"recall\", # Define the type of document i.e recall memory\n",
    "            \"user_id\": user_id,\n",
    "        },\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the vector document in the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.upsert(\n",
    "    vectors=documents,\n",
    "    namespace=PINECONE_NAMESPACE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Query a vector database\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string = \"What do I like?\"\n",
    "user_id = \"1234\"\n",
    "top_k = 10 # This is the number of most similar embeddings to return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = get_embeddings(query_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query the vector database for similar top_k embeddings + filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = index.query(\n",
    "    vector=vector,\n",
    "    filter={\n",
    "        \"user_id\": {\"$eq\": user_id},\n",
    "        \"type\": {\"$eq\": \"recall\"},\n",
    "    },\n",
    "    namespace=PINECONE_NAMESPACE,\n",
    "    include_metadata=True,\n",
    "    top_k=top_k,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the memories list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memories = []\n",
    "if matches := response.get(\"matches\"):\n",
    "    memories = [m[\"metadata\"][\"payload\"] for m in matches]\n",
    "    memories\n",
    "memories"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
